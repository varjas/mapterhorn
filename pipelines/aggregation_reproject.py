import json
import os

import rasterio
import mercantile

import utils

SILENT = True

def create_virtual_raster(tmp_folder, i, source_items):
    vrt_filepath = f'{tmp_folder}/{i}.vrt'
    input_file_list_path = f'{tmp_folder}/{i}-file-list.txt'
    with open(input_file_list_path, 'w') as f:
        for source_item in source_items:
            f.write(f'source-store/{source_item["source"]}/{source_item["filename"]}\n')
    command = f'gdalbuildvrt -overwrite -input_file_list {input_file_list_path} {vrt_filepath}'
    out, err = utils.run_command(command, silent=SILENT)
    if not SILENT:
        print(out, err)
    return vrt_filepath

def get_resolution(zoom):
    tile = mercantile.Tile(x=0, y=0, z=zoom)
    bounds = mercantile.xy_bounds(tile)
    return (bounds.right - bounds.left) / 512

def create_warp(vrt_filepath, vrt_3857_filepath, zoom, aggregation_tile, buffer):
    left, bottom, right, top = mercantile.xy_bounds(aggregation_tile)
    left -= buffer
    bottom -= buffer
    right += buffer
    top += buffer
    resolution = get_resolution(zoom)
    command = f'gdalwarp -of vrt -overwrite '
    command += f'-t_srs EPSG:3857 '
    command += f'-tr {resolution} {resolution} '
    command += f'-te {left} {bottom} {right} {top} '
    command += f'-r cubicspline '
    command += f'-dstnodata -9999 '
    command += f'{vrt_filepath} {vrt_3857_filepath}'
    out, err = utils.run_command(command, silent=SILENT)
    if err.strip() != '':
        raise Exception(f'gdalwarp failed for {vrt_filepath}:\n{out}\n{err}')

def translate(in_filepath, out_filepath):
    command = f'GDAL_CACHEMAX=512 gdal_translate -of COG '
    command += f'-co BIGTIFF=IF_NEEDED -co ADD_ALPHA=YES -co OVERVIEWS=NONE '
    command += f'-co SPARSE_OK=YES -co BLOCKSIZE=512 -co COMPRESS=NONE '
    command += f'{in_filepath} '
    command += f'{out_filepath}'
    out, err = utils.run_command(command, silent=SILENT)
    if err.strip() != '':
        raise Exception(f'gdal_translate failed for {in_filepath}:\n{out}\n{err}')

def contains_nodata_pixels(filepath):
    with rasterio.env.Env(GDAL_CACHEMAX=64):
        with rasterio.open(filepath) as src:
            block_size = 1024
            for row in range(0, src.height, block_size):
                for col in range(0, src.width, block_size):
                    window = rasterio.windows.Window(
                        col_off=col,
                        row_off=row,
                        width=min(block_size, src.width - col),
                        height=min(block_size, src.height - row)
                    )
                    data = src.read(1, window=window)
                    if -9999 in data:
                        return True
    return False

def reproject(filepath):
    _, aggregation_id, filename = filepath.split('/')

    z, x, y, child_z = [int(a) for a in filename.replace('-aggregation.csv', '').split('-')]
    
    aggregation_tile = mercantile.Tile(x=x, y=y, z=z)

    tmp_folder = f'aggregation-store/{aggregation_id}/{aggregation_tile.z}-{aggregation_tile.x}-{aggregation_tile.y}-{child_z}-tmp'
    utils.create_folder(tmp_folder)

    metadata_filepath = f'{tmp_folder}/reprojection.json'
    if os.path.isfile(metadata_filepath):
        print(f'reproject {filename} already done...')
        return

    grouped_source_items = utils.get_grouped_source_items(filepath)
    maxzoom = grouped_source_items[0][0]['maxzoom']
    resolution = get_resolution(maxzoom)

    total_source_files = sum(len(group) for group in grouped_source_items)

    buffer_pixels = 0
    buffer_3857_rounded = 0
    if len(grouped_source_items) > 1 or total_source_files > 1:
        buffer_pixels = int(utils.macrotile_buffer_3857 / resolution)
        buffer_3857_rounded = buffer_pixels * resolution

    tiff_dataset_ids = []
    for i, source_items in enumerate(grouped_source_items):
        vrt_filepath = create_virtual_raster(tmp_folder, i, source_items)
        zoom = maxzoom
        vrt_3857_filepath = f'{tmp_folder}/{i}-3857.vrt'
        create_warp(vrt_filepath, vrt_3857_filepath, zoom, aggregation_tile, buffer_3857_rounded)
        out_filepath = f'{tmp_folder}/{i}-3857.tiff'
        translate(vrt_3857_filepath, out_filepath)
        tiff_dataset_ids.append(source_items[0]['dataset_id'])

        if len(grouped_source_items) > 1 and not contains_nodata_pixels(out_filepath):
            break

    metadata = {
        'buffer_pixels': buffer_pixels,
        'tiff_dataset_ids': tiff_dataset_ids,
    }
    with open(metadata_filepath, 'w') as f:
        json.dump(metadata, f, indent=2)
